{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Logistic Regression leveraging NLTK library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a technique through which you can analyze a piece of text to determine the sentiment behind it. It combines machine learning and natural language processing (NLP) to achieve this. Using basic Sentiment analysis, a program can understand if the sentiment behind a piece of text is positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this sentiment analysis we need very simple 5 steps -\n",
    "1. Preprocess the text by removing extra unwanted words, stop words & punctuation\n",
    "2. Generate frequency metrics has positive or negetive count with respect to each word\n",
    "3. Extract feature map which has [word, postive count, negetive count] \n",
    "4. Divide into train and test and classify using any classifier ( Logistic regression )\n",
    "5. Predict & Evaluate classifier output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yogesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer         # module for stemming\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer,sent_tokenize,word_tokenize   # module for tokenizing strings\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\yogesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess_tweet function cleans the tweet after removing extra stop words, punctuation etc. After this tweet need to be tokenize into words & then words converted into their respective lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweet):\n",
    "    tweets_clean = []\n",
    "    \n",
    "    # Instantiate stemming class\n",
    "    Lemma = WordNetLemmatizer()\n",
    "    \n",
    "    # Create an empty list to store the stems\n",
    "    tweets_lemma = []\n",
    "\n",
    "    stopwords_english = stopwords.words('english') \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
    "    \n",
    "    tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet2)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet2 = re.sub(r'#', '', tweet2)\n",
    "    \n",
    "\n",
    "    tweet_tokens = tokenizer.tokenize(tweet2)\n",
    "    \n",
    "    for word_token in tweet_tokens:\n",
    "        if(word_token not in stopwords_english and word_token not in string.punctuation):\n",
    "            stem_word = Lemma.lemmatize(word_token)\n",
    "            tweets_clean.append(stem_word)\n",
    "    \n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate positive & negetive count for each word occured in the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freq(tweets,label):\n",
    "    ys = label\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    freq = {}\n",
    "\n",
    "    for tweet,y in zip(tweets,ys):\n",
    "        for word in preprocess_tweets(tweet):\n",
    "            pair = (word,y)\n",
    "            if pair in freq:\n",
    "                freq[pair] += 1\n",
    "            else:\n",
    "                freq[pair] = 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build frequency metrics [word, postive count, negetive count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_map(tweet,freq):\n",
    "    clean_word = preprocess_tweets(tweet)\n",
    "    x = np.zeros((1,3))\n",
    "    x[0,0]=1\n",
    "\n",
    "    for word in clean_word:\n",
    "        x[0,1] += freq.get((word,1.0),0)\n",
    "        x[0,2] += freq.get((word,0.0),0)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into two pieces, one for training and one for testing (validation set) \n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freq(train_x, np.squeeze(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i]=extract_feature_map(train_x[i],freqs)\n",
    "\n",
    "y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yogesh\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logistic_reg = LogisticRegression()\n",
    "Logistic_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logistic_reg.predict(extract_feature_map(test_x[0],freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_y = np.zeros(len(test_x))\n",
    "y_pred_proba = pd.DataFrame()\n",
    "for i in range(0,len(test_x)):\n",
    "    Pred_y[i]= Logistic_reg.predict(extract_feature_map(test_x[i],freqs))\n",
    "    y_pred_proba=pd.concat([y_pred_proba,pd.DataFrame(Logistic_reg.predict_proba(extract_feature_map(test_x[i],freqs)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.948930e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.562750e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.011463e-03</td>\n",
       "      <td>9.989885e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.162315e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.354098e-04</td>\n",
       "      <td>9.995646e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.445775e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.359294e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.417759e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.727733e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.444467e-01</td>\n",
       "      <td>5.555332e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1\n",
       "0   4.948930e-12  1.000000e+00\n",
       "0   6.562750e-12  1.000000e+00\n",
       "0   1.011463e-03  9.989885e-01\n",
       "0   1.162315e-11  1.000000e+00\n",
       "0   4.354098e-04  9.995646e-01\n",
       "..           ...           ...\n",
       "0   1.000000e+00  2.445775e-17\n",
       "0   1.000000e+00  4.359294e-17\n",
       "0   1.000000e+00  3.417759e-17\n",
       "0   1.000000e+00  4.727733e-17\n",
       "0   9.444467e-01  5.555332e-02\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2840f22de10>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(test_y,Pred_y),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,precision_score, recall_score,roc_auc_score,r2_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cbd35fe224ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision score\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Precision score\",precision_score(y_true=test_y,y_pred=Pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"recall score\",recall_score(y_true=test_y,y_pred=Pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9925"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"roc_auc_score\",roc_auc_score(y_true=test_y,y_score=Pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
